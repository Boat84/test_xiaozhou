## K-最近邻算法（K-Nearest Neighbors, KNN）是一种简单且常用的监督学习算法，主要用于分类和回归问题。KNN的基本思想是：对于一个新的数据点，根据其与训练集中最近的K个数据点的距离来决定其类别或预测其值。

### 基本概念:
* 训练数据集：已知标签的数据集。
* 距离度量：通常使用欧氏距离（Euclidean distance）来衡量数据点之间的相似度。其他常用的距离度量包括曼哈顿距离（Manhattan distance）和闵可夫斯基距离（Minkowski distance）。
* K值：指在决策过程中考虑的邻居数量。K值的选择对算法性能有重要影响。
### 工作原理
* 选择参数K：即选择最近邻居的数量。
* 计算距离：对于待分类的样本，计算它与训练集中所有样本的距离。
* 选择最近的K个邻居：根据计算的距离从小到大排序，选择前K个距离最小的邻居。
#### 投票或加权平均：
* 对于分类问题，通过邻居中多数类来决定新样本的类别（即多数投票法）。
* 对于回归问题，通过邻居的平均值来预测新样本的值。
##### 优点
* 简单易懂：KNN算法的原理非常直观，容易理解和实现。
* 无参数学习：KNN没有显式的训练过程，只是在预测时计算距离，适合小规模数据集。
##### 缺点
* 计算开销大：需要计算每个样本与训练集中所有样本的距离，预测时的计算复杂度较高，特别是对于大规模数据集。
* 存储需求高：必须存储所有训练数据，因此对存储空间的要求较高。
* 对不平衡数据敏感：在分类问题中，如果某个类的样本数量较多，可能会对结果产生偏差。
#### K值选择(选择合适的K值非常关键)
* K值过小：模型容易受到噪声影响，导致过拟合。
* K值过大：邻居中可能包含太多不相关的样本，导致欠拟合。
* 通常通过交叉验证等方法来选择最优的K值。


### 计算距离：
#### 1.欧氏距离（Euclidean Distance）欧氏距离是最常用的距离度量方法，它计算的是两个点在多维空间中的直线距离。公式如下：
$$\[ d(p, q) = \sqrt{\sum_{i=1}^{n} (p_i - q_i)^2} \]$$
其中，\( p \) 和 \( q \) 是两个 n 维向量，\( p_i \) 和 \( q_i \) 分别是向量 \( p \) 和 \( q \) 在第 \( i \) 维的坐标。
* 特点： 1,欧氏距离在几何空间中表现为两点之间的最短路径（直线距离）。 2,对坐标的变化（缩放、旋转等）敏感。
*应用场景：常用于图像处理、模式识别等领域，适合连续数值特征的数据。

#### 2. 曼哈顿距离 (Manhattan Distance)曼哈顿距离也称为城市街区距离或L1距离，它计算的是两个点之间在各个坐标轴上的绝对距离之和。公式如下：
$$\[ d(p, q) = \sum_{i=1}^{n} |p_i - q_i| \]$$
其中，\( p \) 和 \( q \) 是两个 n 维向量，\( p_i \) 和 \( q_i \) 分别是向量 \( p \) 和 \( q \) 在第 \( i \) 维的坐标。
* 特点：1,曼哈顿距离适用于高维空间中的稀疏向量（大多数坐标为零）。2,对坐标的变化（如缩放）不敏感。
* 应用场景：常用于文本分类、推荐系统等领域，适合离散特征的数据。

#### 3. 明可夫斯基距离 (Minkowski Distance)闵可夫斯基距离是欧氏距离和曼哈顿距离的广义形式，它引入了一个参数𝑝来调整距离计算的方式。公式如下：
$$\[ d(p, q) = \left( \sum_{i=1}^{n} |p_i - q_i|^p \right)^{\frac{1}{p}} \]$$
其中，\( p \) 和 \( q \) 是两个 n 维向量，\( p_i \) 和 \( q_i \) 分别是向量 \( p \) 和 \( q \) 在第 \( i \) 维的坐标。参数 \( p \) 控制距离的度量方式：
* 当 \( p = 1 \) 时，明可夫斯基距离等同于曼哈顿距离。
* 当 \( p = 2 \) 时，明可夫斯基距离等同于欧氏距离。
* p 值越大，距离越接近于“最大距离”，即两个点在所有坐标轴上的最大绝对差值。

#### 总结
* 欧氏距离：适用于连续数值特征，计算点之间的直线距离。
* 曼哈顿距离：适用于离散特征和稀疏向量，计算各坐标轴上绝对距离之和。
* 闵可夫斯基距离：作为欧氏和曼哈顿距离的泛化形式，可以调整参数 𝑝 来适应不同数据类型和应用场景。不同距离度量方法的选择应根据具体数据集的特点和应用需求来确定。例如，在文本数据处理中，由于特征通常是高维稀疏向量，曼哈顿距离或闵可夫斯基距离（适当选择 𝑝）可能更为适用。而在图像处理等连续特征的数据中，欧氏距离可能更合适。


